import cv2
import dlib
import numpy as np
import os
import pickle
from datetime import datetime
import time
from threading import Thread, Event, Lock
import warnings
from collections import deque
import signal
import json
from enum import Enum, auto
import grpc
from concurrent import futures
import faiss

# Protocol Buffer imports would be here in a full implementation
# import face_recognition_pb2
# import face_recognition_pb2_grpc

class FaceRecognitionState(Enum):
    IDLE = auto()
    RECOGNIZING = auto()
    REGISTERING = auto()
    VERIFYING_LIVENESS = auto()

class FaceDatabase:
    """Encapsulated face database with metadata support"""
    def __init__(self, db_file="face_db.dat"):
        self.db_file = db_file
        self.data = {}
        self.lock = Lock()
        self.index = None  # FAISS index for vector search
        self.load_database()

    def load_database(self):
        """Load database from file and initialize index"""
        if os.path.exists(self.db_file):
            try:
                with open(self.db_file, 'rb') as f:
                    self.data = pickle.load(f)
                self._build_index()
                print(f"Loaded {len(self.data)} known faces")
            except Exception as e:
                warnings.warn(f"Failed to load database: {e}")
                self.data = {}

    def save_database(self):
        """Save database to file"""
        with self.lock:
            try:
                with open(self.db_file, 'wb') as f:
                    pickle.dump(self.data, f)
            except Exception as e:
                warnings.warn(f"Failed to save database: {e}")

    def _build_index(self):
        """Build FAISS index for efficient vector search"""
        if not self.data:
            self.index = None
            return
            
        encodings = np.array([v['encoding'] for v in self.data.values()])
        self.index = faiss.IndexFlatL2(encodings.shape[1])
        self.index.add(encodings)

    def add_face(self, face_id, encoding, metadata=None):
        """Add a new face to the database"""
        with self.lock:
            self.data[face_id] = {
                'encoding': encoding,
                'timestamp': datetime.now().isoformat(),
                'metadata': metadata or {
                    'registered_by': 'system',
                    'device_id': 'default',
                    'last_accessed': datetime.now().isoformat()
                }
            }
            self._build_index()
        self.save_database()

    def update_face(self, face_id, encoding=None, metadata=None):
        """Update an existing face entry"""
        with self.lock:
            if face_id not in self.data:
                return False
                
            if encoding is not None:
                self.data[face_id]['encoding'] = encoding
            if metadata is not None:
                self.data[face_id]['metadata'].update(metadata)
                
            self.data[face_id]['metadata']['last_accessed'] = datetime.now().isoformat()
            self._build_index()
            
        self.save_database()
        return True

    def find_similar(self, encoding, threshold=0.6, top_k=5):
        """Find similar faces using vector search"""
        if not self.data or self.index is None:
            return []
            
        encoding = np.array(encoding).astype('float32').reshape(1, -1)
        distances, indices = self.index.search(encoding, top_k)
        
        results = []
        known_ids = list(self.data.keys())
        
        for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
            if idx == -1 or dist > threshold:
                continue
                
            face_id = known_ids[idx]
            results.append({
                'face_id': face_id,
                'distance': float(dist),
                'confidence': 1 - (dist / threshold),
                'metadata': self.data[face_id]['metadata']
            })
        
        return results

class LivenessDetector:
    """Basic liveness detection using blink analysis"""
    def __init__(self):
        self.eye_aspect_ratio_threshold = 0.25
        self.consecutive_frames = 0
        self.blink_count = 0
        self.required_blinks = 2
        
    def detect_blink(self, landmarks):
        """Simple blink detection using eye aspect ratio"""
        # Left eye landmarks (points 36-41)
        left_eye = landmarks[36:42]
        # Right eye landmarks (points 42-47)
        right_eye = landmarks[42:48]
        
        # Calculate eye aspect ratios
        left_ear = self._eye_aspect_ratio(left_eye)
        right_ear = self._eye_aspect_ratio(right_eye)
        
        # Average the eye aspect ratio
        ear = (left_ear + right_ear) / 2.0
        
        if ear < self.eye_aspect_ratio_threshold:
            self.consecutive_frames += 1
        else:
            if self.consecutive_frames >= 3:  # Minimum frames for a blink
                self.blink_count += 1
            self.consecutive_frames = 0
            
        return self.blink_count >= self.required_blinks
    
    def _eye_aspect_ratio(self, eye):
        """Compute eye aspect ratio"""
        # Vertical distances
        A = np.linalg.norm(eye[1] - eye[5])
        B = np.linalg.norm(eye[2] - eye[4])
        
        # Horizontal distance
        C = np.linalg.norm(eye[0] - eye[3])
        
        return (A + B) / (2.0 * C)

class FaceRecognitionNode:
    """Individual camera node with processing capabilities"""
    def __init__(self, camera_id=0, db=None):
        self.camera_id = camera_id
        self.db = db or FaceDatabase()
        self.liveness_detector = LivenessDetector()
        
        # Initialize models
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
        self.face_encoder = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")
        
        # Camera setup
        self.cap = cv2.VideoCapture(camera_id)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # Runtime state
        self.state = FaceRecognitionState.IDLE
        self.running = Event()
        self.current_frame = None
        self.results = []
        self.frame_count = 0
        self.fps = 0
        self.lock = Lock()
        
        # Registration state
        self.register_name = ""
        self.register_encoding = None
        self.register_landmarks = None
        
        # Signal handling
        signal.signal(signal.SIGINT, self.shutdown_handler)
        signal.signal(signal.SIGTERM, self.shutdown_handler)

    def shutdown_handler(self, signum, frame):
        """Handle shutdown signals gracefully"""
        print(f"\nReceived signal {signum}, shutting down...")
        self.running.clear()

    def process_frame(self, frame):
        """Process a single frame based on current state"""
        if self.state == FaceRecognitionState.IDLE:
            return
            
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        faces = self.detector(rgb, 1)
        
        if not faces:
            self.results = []
            return
            
        if self.state == FaceRecognitionState.RECOGNIZING:
            self._process_recognition(rgb, faces)
        elif self.state == FaceRecognitionState.REGISTERING:
            self._process_registration(rgb, faces)
        elif self.state == FaceRecognitionState.VERIFYING_LIVENESS:
            self._process_liveness(rgb, faces)

    def _process_recognition(self, rgb, faces):
        """Process frame for face recognition"""
        results = []
        
        for face in faces:
            landmarks = self.predictor(rgb, face)
            encoding = self.face_encoder.compute_face_descriptor(rgb, landmarks)
            
            matches = self.db.find_similar(encoding)
            if matches:
                best_match = matches[0]
                results.append({
                    'face_id': best_match['face_id'],
                    'confidence': best_match['confidence'],
                    'rect': (face.left(), face.top(), face.right(), face.bottom()),
                    'metadata': best_match['metadata']
                })
            else:
                results.append({
                    'face_id': 'unknown',
                    'confidence': 0,
                    'rect': (face.left(), face.top(), face.right(), face.bottom())
                })
        
        with self.lock:
            self.results = results

    def _process_registration(self, rgb, faces):
        """Process frame for face registration"""
        if len(faces) != 1:
            return
            
        face = faces[0]
        landmarks = self.predictor(rgb, face)
        encoding = self.face_encoder.compute_face_descriptor(rgb, landmarks)
        
        with self.lock:
            self.register_encoding = encoding
            self.register_landmarks = landmarks

    def _process_liveness(self, rgb, faces):
        """Process frame for liveness verification"""
        if len(faces) != 1:
            return
            
        face = faces[0]
        landmarks = self.predictor(rgb, face)
        
        # Convert landmarks to numpy array of points
        landmarks_np = np.array([[p.x, p.y] for p in landmarks.parts()])
        
        # Check for blinks
        if self.liveness_detector.detect_blink(landmarks_np):
            encoding = self.face_encoder.compute_face_descriptor(rgb, landmarks)
            with self.lock:
                self.register_encoding = encoding
                self.state = FaceRecognitionState.REGISTERING

    def start_recognition(self):
        """Start continuous face recognition"""
        self.state = FaceRecognitionState.RECOGNIZING
        self.running.set()
        Thread(target=self._capture_loop, daemon=True).start()

    def start_registration(self, name, verify_liveness=False):
        """Start face registration process"""
        if not name.strip():
            return False
            
        if name in self.db.data:
            print(f"Name '{name}' exists. Overwrite? (y/n)")
            choice = input().lower()
            if choice != 'y':
                return False
                
        self.register_name = name.strip()
        
        if verify_liveness:
            self.state = FaceRecognitionState.VERIFYING_LIVENESS
            self.liveness_detector.blink_count = 0
            print("Please blink naturally for liveness verification")
        else:
            self.state = FaceRecognitionState.REGISTERING
            
        return True

    def complete_registration(self):
        """Complete the registration process"""
        if self.register_encoding is None or not self.register_name:
            return False
            
        metadata = {
            'registered_by': 'user',
            'device_id': f'camera_{self.camera_id}',
            'registration_date': datetime.now().isoformat()
        }
        
        self.db.add_face(self.register_name, self.register_encoding, metadata)
        
        # Reset registration state
        self.register_name = ""
        self.register_encoding = None
        self.state = FaceRecognitionState.RECOGNIZING
        
        return True

    def _capture_loop(self):
        """Main capture and processing loop"""
        last_time = time.time()
        fps_history = deque(maxlen=10)
        
        while self.running.is_set():
            start_time = time.time()
            
            ret, frame = self.cap.read()
            if not ret:
                continue
                
            with self.lock:
                self.current_frame = frame.copy()
                self.frame_count += 1
                
                # Skip frames based on processing load
                if self.frame_count % 3 == 0:
                    self.process_frame(frame)
                
                # Calculate FPS
                fps_history.append(1.0 / (time.time() - last_time))
                self.fps = sum(fps_history) / len(fps_history)
                last_time = time.time()
            
            # Maintain reasonable processing rate
            processing_time = time.time() - start_time
            if processing_time < 0.03:  # ~30fps
                time.sleep(0.03 - processing_time)

    def get_results(self):
        """Get current recognition results"""
        with self.lock:
            return self.results.copy()

    def get_frame_with_overlay(self):
        """Get current frame with recognition overlay"""
        frame = self.current_frame.copy()
        
        # Draw recognition results
        for result in self.results:
            x1, y1, x2, y2 = result['rect']
            color = (0, 255, 0) if result['face_id'] != 'unknown' else (0, 0, 255)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            label = f"{result['face_id']} ({result['confidence']:.2f})"
            cv2.putText(frame, label, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Draw system state
        state_text = f"State: {self.state.name}"
        cv2.putText(frame, state_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Draw FPS
        cv2.putText(frame, f"FPS: {self.fps:.1f}", (frame.shape[1]-120, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame

    def stop(self):
        """Stop the capture and processing"""
        self.running.clear()
        self.cap.release()

class FaceRecognitionServer:
    """Central server for multi-camera coordination"""
    def __init__(self):
        self.nodes = {}
        self.db = FaceDatabase()
        
        # Initialize gRPC server (implementation would be in separate files)
        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
        # face_recognition_pb2_grpc.add_FaceRecognitionServiceServicer_to_server(
        #     FaceRecognitionServicer(self), self.server)
        self.server.add_insecure_port('[::]:50051')
        
    def add_camera_node(self, camera_id):
        """Add a new camera node"""
        if camera_id in self.nodes:
            return False
            
        node = FaceRecognitionNode(camera_id, self.db)
        self.nodes[camera_id] = node
        node.start_recognition()
        return True
        
    def start(self):
        """Start the server and all nodes"""
        self.server.start()
        print("Server started on port 50051")
        
    def stop(self):
        """Stop the server and all nodes"""
        for node in self.nodes.values():
            node.stop()
        self.server.stop(0)

if __name__ == "__main__":
    # Example usage
    print("Starting face recognition system...")
    
    # Initialize single camera node (or server in production)
    node = FaceRecognitionNode(0)
    node.start_recognition()
    
    try:
        while True:
            frame = node.get_frame_with_overlay()
            cv2.imshow("Face Recognition", frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                name = input("Enter name to register: ")
                if name:
                    node.start_registration(name, verify_liveness=True)
                    
            # Check if registration needs completion
            if node.state == FaceRecognitionState.REGISTERING and node.register_encoding:
                if node.complete_registration():
                    print("Registration successful!")
                else:
                    print("Registration failed")
                    
    except KeyboardInterrupt:
        print("\nShutting down...")
    finally:
        node.stop()
        cv2.destroyAllWindows()